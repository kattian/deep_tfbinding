#!/usr/bin/env python

import os
from os.path import basename
import argparse

ROOT_DIR   = os.getenv('TFNET_ROOT', "../../") 
scriptDir  = ROOT_DIR + "/scripts/"
dataDir    = ROOT_DIR + "/ENCODE_data/"
genomeDir  = ROOT_DIR + "/genome/"
resultsDir = "./"
logDir     = resultsDir + "log/"
tmpDir     = None

min_from_edge = 5000

import logging
logging.basicConfig(
        format='%(asctime)s %(levelname)-5s %(message)s',
        level=logging.DEBUG,
        datefmt='%Y-%m-%d %H:%M:%S')

chrom_sizes = {}
def load_chrom_sizes(chrom_sizes_fn):
    global chrom_sizes
    chrom_sizes = {}
    with open(chrom_sizes_fn) as genome_fh:
        for line in genome_fh:
            chrom, size = line.split()
            chrom_sizes[chrom.strip()] = int(size)
    

def make_windows(in_name, out_name, bin_size = 200, stride = 50, expand = True, tasks = 0):
    """
        takes in regions and expands region lengths to be a multiple of stride (50)
        outputs a list of regions, result of sliding window of length bin_size (200)
    """
    label_str = ""
    for i in range(tasks) :
        label_str = label_str + "\t0"

    with open(in_name,'r') as tsvin, open(out_name, 'w') as tsvout:
        # for row in tsvin:
        for cnt, line in enumerate(tsvin):
            row = line.split()
            chrom = row[0]
            start = int(row[1])
            end   = int(row[2])

            if chrom[3] == 'M' or chrom[3] == 'm':
                continue
            if len(chrom) > 5:
                continue

            peak_length = end - start
            if expand :
                # total_length = stride * ceiling = smallest multiple of stride greater than peak_length
                total_length = stride * int( (peak_length + stride - 1 )/stride )
            else : 
                total_length = peak_length # no expand
                

            extend_left = int((total_length - peak_length)/2)
            extend_left = 0
            extend_right = total_length - peak_length - extend_left

            left  = start - extend_left
            right = end + extend_right

            # write out the new "unified" intervals
            right_max = chrom_sizes[chrom] - min_from_edge
            for le in range(max(left, min_from_edge), 
                            min(right, right_max) - bin_size + 1, stride):
                tsvout.write(chrom + "\t" + str(le) + "\t" + str(le + bin_size) + label_str + "\n")


import contextlib
@contextlib.contextmanager
def dummy_context_mgr():
    yield None


def label_regions_fast(region, positive, ambiguous, labels):
    """
        label regions for one task
        O(n) to go through intervals in region file and label them
        assuming regions, positives, ambiguous files are all sorted

        Parameters
        ----------
        region:     input file with list of intervals to be labeled
        positive:   input file with list of positive intersecting intervals (subset of region)
        ambiguous:  input file with list of ambiguous intersecting intervals (subset of region)
        labels:     output file with one column of labels
    """
    
    # Open the file with read only permit
    with open(region,'r') as reg, open(positive, 'r') as pos, open (labels, 'w') as lab:
        
        # conditional with block
        with open(ambiguous, 'r') if ambiguous != None else dummy_context_mgr() as amb:

            # read in p_line, r_line, and a_line from files
            p_line = pos.readline()
            r_line = reg.readline()
            if ambiguous != None:
                a_line = amb.readline()
                read_a = True
            else:
                a_line = None
                read_a = False

            # iterate through regions & determine labels
            while r_line:
                read_p = False # if p matched r and we should move to next positive interval
                read_a = False # if a matched r ...
                if r_line == p_line: # positive
                    out = 1
                    read_p = True
                    if r_line == a_line:
                        read_a = True
                elif r_line == a_line: # ambiguous
                    out = -1
                    read_a = True
                else: # negative
                    out = 0

                lab.write(str(out) + "\n")

                r_line = reg.readline()
                if read_p:
                    p_line = pos.readline()
                if read_a:
                    a_line = amb.readline()
# can be simplified if we use intersect -c


def label_regions_multitask(labels_multitask, chrom_sizes_fn, positives, 
                            ambiguous = None, regions = None,
                            bin_size=200, flank_size=400, stride=50,
                            n_jobs=1, genome='hg19',
                            min_bin_distance_to_chrom_edge=5000):
    """ 
    generate labels for multitask training

    Parameters
    ----------
    labels_multitask : output labels file.
    chrom_sizes_fn   : file that contains the sizes of reference genomes.
    positives        : the true positives, a list of paths, one for each experiment,
                       mandatory.
    ambiguous        : the ambiguous set, a list of paths, one for each experiment,
                       optional. if present, must have the same length as the 
                       positives, so that we can match ambiguous to the positives
    regions          : (not supported yet) 
                       total regions being labeled. If not specified, 
                       use the union of positives
    """
    #os.system("mkdir -p " + tmpDir)

    load_chrom_sizes(chrom_sizes_fn)

    ############################################
    ### positives
    
    # unzip the original positive input interval files from each task to tmpDir
    p_unzips = []
    for p_orig in positives:
        if p_orig[-3:] == ".gz":
            # basename extracts the last part of the path, the filename
            p_unzip = tmpDir + basename(p_orig[:-3]) # remove ".gz" from filename
            os.system("pigz -d -c " + p_orig + " | bedtools sort > " + p_unzip) # unzip and sort p_orig to p_unzip
        else:
            p_unzip = tmpDir + basename(p_orig)
            os.system("cat "       + p_orig + " | bedtools sort > " + p_unzip) # copy and sort p_orig to p_unzip
        p_unzips.append(p_unzip)

    ############################################
    ### ambigous

    # unzip all original ambiguous input intervals to tmpDir
    if ambiguous != None:
        assert(len(positives) == len(ambiguous)) # ensure same number of tasks
        
        a_unzips = []
        for a_orig in ambiguous:
            if a_orig == None:
                a_unzip = ""
            else:
                if a_orig[-3:] == ".gz":
                    a_unzip = tmpDir + basename(a_orig[:-3]) # remove ".gz"
                    os.system("pigz -d -c " + a_orig + " | bedtools sort > " + a_unzip)
                else:
                    a_unzip = tmpDir + basename(a_orig)
                    os.system("cat "       + a_orig + " | bedtools sort > " + a_unzip)
            a_unzips.append(a_unzip)

    ############################################
    
    # if no background regions were specified, use the union of positives as regions
    if regions == None:
        # sort and merge the positives 
        tmp_regions = tmpDir + "_tmp_regions.tsv"
        cmd = "cat " + " ".join(p_unzips) + \
            " | cut -f 1-3 | bedtools sort | bedtools merge > " + tmp_regions
        os.system(cmd)
        tmp_comp_window_regions = None
    else:
        # sort and merge the positives and ambiguous
        tmp_regions = tmpDir + "_tmp_regions.tsv"
        cmd = "cat " + " ".join(p_unzips) + " " + " ".join(a_unzips) + \
            " | cut -f 1-3 | bedtools slop -i stdin -b " + str((bin_size/2)) + \
            " -g " + chrom_sizes_fn + " | bedtools sort | bedtools merge > " + tmp_regions
        os.system(cmd)

        tmp_comp_regions = tmpDir + "_tmp_comp_regions.tsv"

        #cmd = "bedtools complement -i " + tmp_regions + " -g " + \
        #    chrom_sizes_fn + " > " + tmp_comp_regions)

        cmd = "bedtools subtract -a " + regions + " -b " + \
              tmp_regions + " > " + tmp_comp_regions
        os.system(cmd)

        tmp_comp_window_regions = tmpDir + "_tmp_comp_window_regions.tsv"
        expanded_window_size = bin_size + 2 * flank_size
        make_windows(tmp_comp_regions, tmp_comp_window_regions, 
                     bin_size=expanded_window_size, stride=expanded_window_size,
                     expand=False, tasks=len(positives))     

    regions = tmp_regions

    logging.info("LABEL_REGIONS sort merge done")

    # unify the core region lengths to multiple of strides and make windows
    tmp_core_regions = tmpDir + "_tmp_core_regions.tsv"
    make_windows(regions, tmp_core_regions, bin_size=bin_size, stride=stride)     

    # generate intersects with positives
    pos_intersects = []
    for p in p_unzips:
        p_intersect = tmpDir + "_tmp_pint_" + basename(p)
        os.system("bedtools intersect -a " + tmp_core_regions + " -b " + p + \
            " -sorted -wa -f 0.5 -F 0.5 -e -u > " + p_intersect) # add -c later
        #os.system("bedtools intersect -a " + tmp_core_regions + " -b " + p + \
        #    " -sorted -wa -f 0.5 -F 0.5 -e -c | cut -f 4 > " + p_intersect)
        pos_intersects.append(p_intersect)

    # generate intersects with ambiguous
    amb_intersects = []
    for a in a_unzips:
        a_intersect = tmpDir + "_tmp_aint_" + basename(a)
        os.system("bedtools intersect -a " + tmp_core_regions + " -b " + a + \
            " -sorted -wa -f 0.5 -F 0.5 -e -u > " + a_intersect) # add -c later
        #os.system("bedtools intersect -a " + tmp_core_regions + " -b " + a + \
        #    " -sorted -wa -f 0.5 -F 0.5 -e -c | cut -f 4 > " + a_intersect)
        amb_intersects.append(a_intersect)

    # generate expanded regions
    tmp_expanded_regions = tmpDir + "_tmp_expanded_regions.tsv"
    os.system("bedtools slop -i " + tmp_core_regions + " -g " + \
        chrom_sizes_fn + " -b " + str(flank_size) + " > " + tmp_expanded_regions)

    logging.info("LABEL_REGIONS intersect done")

    # label regions for each task and paste to the regions
    for i in range(len(positives)):
        tmp_labels = tmpDir + "_tmp_labels_" + str(i) + ".tsv"
        if ambiguous:
            a_intersect = amb_intersects[i]
        else:
            a_intersect = None
        label_regions_fast(tmp_core_regions, pos_intersects[i], a_intersect, tmp_labels)
        tmp_paste = tmpDir + "_tmp_paste"
        os.system("paste " + tmp_expanded_regions + " " + tmp_labels + " > " + tmp_paste)
        os.system("mv -f " + tmp_paste + " " + tmp_expanded_regions)

    if tmp_comp_window_regions != None:
        os.system("cat " + tmp_comp_window_regions + " >> " + tmp_expanded_regions)

    logging.info("LABEL_REGIONS labels done")
    # shuffle the lines
    os.system("shuf " + tmp_expanded_regions + " | pigz > " + labels_multitask)

    # clean up temp files generated
    #os.system("rm -f " + tmp_regions + ";" +
    #          "rm -f " + tmp_core_regions + ";" +
    #          "rm -f " + tmp_expanded_regions + ";")

    logging.info("LABEL_REGIONS ALL DONE *****")


# argument parsing borrowed from tf-dragonn labelregions so that we are compatable
def parse_args(args = None):
    parser = argparse.ArgumentParser('tfdragonn labelregions',
                                     description='Generate fixed length regions and their'
                                     ' labels for each dataset.',
                                     formatter_class=argparse.RawTextHelpFormatter)
    #parser.add_argument('--raw-intervals-config-file', type=os.path.abspath, default=None,
    #                    help='Includes task names and a map from dataset id -> raw interval file')
    parser.add_argument('--positives', type=str, default=None, help='positive bed files for each task, separated by commas.')
    parser.add_argument('--ambiguous', type=str, default=None, help='ambiguous bed files for each task, separated by commas.')
    parser.add_argument('--background', type=str, default=None, help='background bed file.')
    parser.add_argument('--prefix', type=str, required=True, help='prefix of output files')
    parser.add_argument('--n-jobs', type=int, default=1,
                        help='num of processes.\nDefault: 1.')
    parser.add_argument('--bin-size', type=int, default=200,
                        help='size of bins for labeling.\nDefault: 200.')
    parser.add_argument('--flank-size', type=int, default=400,
                        help='size of flanks around labeled bins.\nDefault: 400.')
    parser.add_argument('--stride', type=int, default=50,
                        help='spacing between consecutive bins.\nDefault: 50.')
    parser.add_argument('--genome', type=str, default='hg19',
                        help='Genome name.\nDefault: hg19.'
                        '\nOptions: hg18, hg38, mm9, mm10, dm3, dm6.')
    #parser.add_argument('--logdir', type=os.path.abspath,
    #                    help='Logging directory', default=None, required=False)
    args = parser.parse_args(args)
    return args


def run_label_regions_from_args():
    args = parse_args()
    if args.positives is not None: # and args.background is not None:
        positives = args.positives.split(',')
        if args.ambiguous is not None:
            ambiguous = args.ambiguous.split(',')
            assert len(ambiguous) == len(positives)
        else:
            ambiguous = None
        path_to_dataset_intervals_file = os.path.abspath("{}.intervals_file.tsv.gz".format(args.prefix))
        #print(path_to_dataset_intervals_file)
        label_regions_multitask(path_to_dataset_intervals_file,
                                genomeDir + "hg19.chrom.sizes", 
                                positives, ambiguous=ambiguous, regions=args.background, 
                                bin_size=args.bin_size, flank_size=args.flank_size, 
                                stride=args.stride, genome=args.genome, n_jobs=args.n_jobs)
    else:
        raise RuntimeError("Must pass in positives, background, and task names!")

# guarantee to clean up tmp dir
import contextlib
import tempfile
import shutil

@contextlib.contextmanager
def make_temp_directory():
    temp_dir = tempfile.mkdtemp(dir = ".", prefix = "_tmp_")
    try:
        yield temp_dir
    finally:
        #shutil.rmtree(temp_dir)
        pass


if __name__ == '__main__':
    with make_temp_directory() as temp_dir:
        global tmpDir
        tmpDir = temp_dir + "/"
        run_label_regions_from_args()

