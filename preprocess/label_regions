#!/usr/bin/env python

import os
from os.path import basename
import argparse

tmpDir    = "./tmp/"
genomeDir = "../genome/"


def unify_core_lengths(in_name, out_name, bin_size = 200, stride = 50):
    """
        takes in regions and expands region lengths to be a multiple of stride (50)
        outputs a list of regions, result of sliding window of length bin_size (200)
    """
    with open(in_name,'r') as tsvin, open(out_name, 'w') as tsvout:
        # for row in tsvin:
        for cnt, line in enumerate(tsvin):
            row = line.split()
            chrom = row[0]
            start = int(row[1])
            end   = int(row[2])

            peak_length = end - start
            total_length = stride * int( (peak_length + stride - 1 )/stride )
            # total_length = stride * ceiling = smallest multiple of stride greater than peak_length

            extend_left = int((total_length - peak_length)/2)
            extend_left = 0
            extend_right = total_length - peak_length - extend_left

            left = start - extend_left
            right = end + extend_right

            # write out the new "unified" intervals
            for le in range(left, right - bin_size + 1, stride):
                tsvout.write(chrom + "\t" + str(le) + "\t" + str(le + bin_size) + "\n")


import contextlib
@contextlib.contextmanager
def dummy_context_mgr():
    yield None


def label_regions_fast(region, positive, ambiguous, labels):
    """
        label regions for one task
        O(n) to go through intervals in region file and label them
        assuming regions, positives, ambiguous files are all sorted

        Parameters
        ----------
        region:     input file with list of intervals to be labeled
        positive:   input file with list of positive intersecting intervals (subset of region)
        ambiguous:  input file with list of ambiguous intersecting intervals (subset of region)
        labels:     output file with one column of labels
    """
    
    # Open the file with read only permit
    with open(region,'r') as reg, open(positive, 'r') as pos, open (labels, 'w') as lab:
        
        # conditional with block
        with open(ambiguous, 'r') if ambiguous != None else dummy_context_mgr() as amb:

            # read in p_line, r_line, and a_line from files
            p_line = pos.readline()
            r_line = reg.readline()
            if ambiguous != None:
                a_line = amb.readline()
                read_a = True
            else:
                a_line = None
                read_a = False

            # iterate through regions & determine labels
            while r_line:
                read_p = False # if p matched r and we should move to next positive interval
                read_a = False # if a matched r ...
                if r_line == p_line: # positive
                    out = 1
                    read_p = True
                    if r_line == a_line:
                        read_a = True
                elif r_line == a_line: # ambiguous
                    out = -1
                    read_a = True
                else: # negative
                    out = 0

                lab.write(str(out) + "\n")

                r_line = reg.readline()
                if read_p:
                    p_line = pos.readline()
                if read_a:
                    a_line = amb.readline()
# can be simplified if we use intersect -c


def label_regions_multitask(labels_multitask, chrom_sizes, positives, 
                            ambiguous = None, regions = None,
                            bin_size=200, flank_size=400, stride=50,
                            n_jobs=1, genome='hg19',
                            min_bin_distance_to_chrom_edge=5000):
    """ 
    generate labels for multitask training

    Parameters
    ----------
    labels_multitask : output labels file.
    chrom_sizes      : file that contains the sizes of reference genomes.
    positives        : the true positives, a list of paths, one for each experiment,
                       mandatory.
    ambiguous        : the ambiguous set, a list of paths, one for each experiment,
                       optional. if present, must have the same length as the 
                       positives, so that we can match ambiguous to the positives
    regions          : (not supported yet) 
                       total regions being labeled. If not specified, 
                       use the union of positives
    """
    os.system("mkdir -p " + tmpDir)

    ############################################
    ### positives
    
    # unzip the original positive input interval files from each task to tmpDir
    p_unzips = []
    for p_orig in positives:
        if p_orig[-3:] == ".gz":
            # basename extracts the last part of the path, the filename
            p_unzip = tmpDir + basename(p_orig[:-3]) # remove ".gz" from filename
            os.system("gunzip -c " + p_orig + " | bedtools sort > " + p_unzip) # unzip and sort p_orig to p_unzip
        else:
            p_unzip = tmpDir + basename(p_orig)
            os.system("cat "       + p_orig + " | bedtools sort > " + p_unzip) # copy and sort p_orig to p_unzip
        p_unzips.append(p_unzip)

    ############################################
    ### ambigous

    # unzip all original ambiguous input intervals to tmpDir
    if ambiguous != None:
        assert(len(positives) == len(ambiguous)) # ensure same number of tasks
        
        a_unzips = []
        for a_orig in ambiguous:
            if a_orig == None:
                a_unzip = ""
            else:
                if a_orig[-3:] == ".gz":
                    a_unzip = tmpDir + basename(a_orig[:-3]) # remove ".gz"
                    os.system("gunzip -c " + a_orig + " | bedtools sort > " + a_unzip)
                else:
                    a_unzip = tmpDir + basename(a_orig)
                    os.system("cat "       + a_orig + " | bedtools sort > " + a_unzip)
            a_unzips.append(a_unzip)

    ############################################
    
    # if no background regions were specified, use the union of positives as regions
    if regions == None:
        # sort and merge the positives 
        tmp_regions = tmpDir + "_tmp_peaks_merge.tsv"
        cmd = "cat " + " ".join(p_unzips) + \
            " | cut -f 1-3 | bedtools sort | bedtools merge > " + tmp_regions
        os.system(cmd)
        regions = tmp_regions

    print("LABEL_REGIONS sort merge done")

    # unify the core region lengths to multiple of strides
    tmp_core_regions = tmpDir + "_tmp_core_regions.tsv"
    unify_core_lengths(regions, tmp_core_regions, bin_size=bin_size, stride=stride)     

    # generate intersects with positives
    pos_intersects = []
    for p in p_unzips:
        p_intersect = tmpDir + "_tmp_pint_" + basename(p)
        os.system("bedtools intersect -a " + tmp_core_regions + " -b " + p + \
            " -sorted -wa -f 0.5 -F 0.5 -e -u > " + p_intersect) # add -c later
        #os.system("bedtools intersect -a " + tmp_core_regions + " -b " + p + \
        #    " -sorted -wa -f 0.5 -F 0.5 -e -c | cut -f 4 > " + p_intersect)
        pos_intersects.append(p_intersect)

    # generate intersects with ambiguous
    amb_intersects = []
    for a in a_unzips:
        a_intersect = tmpDir + "_tmp_aint_" + basename(a)
        os.system("bedtools intersect -a " + tmp_core_regions + " -b " + a + \
            " -sorted -wa -f 0.5 -F 0.5 -e -u > " + a_intersect) # add -c later
        #os.system("bedtools intersect -a " + tmp_core_regions + " -b " + a + \
        #    " -sorted -wa -f 0.5 -F 0.5 -e -c | cut -f 4 > " + a_intersect)
        amb_intersects.append(a_intersect)

    # generate expanded regions
    tmp_expanded_regions = tmpDir + "_tmp_expanded_regions.tsv"
    os.system("bedtools slop -i " + tmp_core_regions + " -g " + \
        chrom_sizes + " -b " + str(flank_size) + " > " + tmp_expanded_regions)

    print("LABEL_REGIONS intersect done")

    # label regions for each task and paste to the regions
    for i in range(len(positives)):
        tmp_labels = tmpDir + "_tmp_labels_" + str(i) + ".tsv"
        if ambiguous:
            a_intersect = amb_intersects[i]
        else:
            a_intersect = None
        label_regions_fast(tmp_core_regions, pos_intersects[i], a_intersect, tmp_labels)
        tmp_paste = tmpDir + "_tmp_paste"
        os.system("paste " + tmp_expanded_regions + " " + tmp_labels + " > " + tmp_paste)
        os.system("mv -f " + tmp_paste + " " + tmp_expanded_regions)

    print("LABEL_REGIONS labels done")
    # shuffle the lines
    os.system("shuf " + tmp_expanded_regions + " | gzip > " + labels_multitask)

    # clean up temp files generated
    os.system("rm -f " + tmp_regions + ";" +
              "rm -f " + tmp_core_regions + ";" +
              "rm -f " + tmp_expanded_regions + ";")

    print("LABEL_REGIONS ALL DONE *****")


# argument parsing borrowed from tf-dragonn labelregions so that we are compatable
def parse_args(args = None):
    parser = argparse.ArgumentParser('tfdragonn labelregions',
                                     description='Generate fixed length regions and their'
                                     ' labels for each dataset.',
                                     formatter_class=argparse.RawTextHelpFormatter)
    #parser.add_argument('--raw-intervals-config-file', type=os.path.abspath, default=None,
    #                    help='Includes task names and a map from dataset id -> raw interval file')
    parser.add_argument('--positives', type=str, default=None, help='positive bed files for each task, separated by commas.')
    parser.add_argument('--ambiguous', type=str, default=None, help='ambiguous bed files for each task, separated by commas.')
    parser.add_argument('--background', type=str, default=None, help='background bed file.')
    parser.add_argument('--prefix', type=str, required=True, help='prefix of output files')
    parser.add_argument('--n-jobs', type=int, default=1,
                        help='num of processes.\nDefault: 1.')
    parser.add_argument('--bin-size', type=int, default=200,
                        help='size of bins for labeling.\nDefault: 200.')
    parser.add_argument('--flank-size', type=int, default=400,
                        help='size of flanks around labeled bins.\nDefault: 400.')
    parser.add_argument('--stride', type=int, default=50,
                        help='spacing between consecutive bins.\nDefault: 50.')
    parser.add_argument('--genome', type=str, default='hg19',
                        help='Genome name.\nDefault: hg19.'
                        '\nOptions: hg18, hg38, mm9, mm10, dm3, dm6.')
    #parser.add_argument('--logdir', type=os.path.abspath,
    #                    help='Logging directory', default=None, required=False)
    args = parser.parse_args(args)
    return args


def run_label_regions_from_args():
    args = parse_args()
    if args.positives is not None: # and args.background is not None:
        positives = args.positives.split(',')
        if args.ambiguous is not None:
            ambiguous = args.ambiguous.split(',')
            assert len(ambiguous) == len(positives)
        else:
            ambiguous = None
        path_to_dataset_intervals_file = os.path.abspath("{}.intervals_file.tsv.gz".format(args.prefix))
        #print(path_to_dataset_intervals_file)
        label_regions_multitask(path_to_dataset_intervals_file,
                                genomeDir + "hg19.chrom.sizes", 
                                positives, ambiguous=ambiguous, regions=args.background, 
                                bin_size=args.bin_size, flank_size=args.flank_size, 
                                stride=args.stride, genome=args.genome, n_jobs=args.n_jobs)
    else:
        raise RuntimeError("Must pass in positives, background, and task names!")

if __name__ == '__main__':
    run_label_regions_from_args()

